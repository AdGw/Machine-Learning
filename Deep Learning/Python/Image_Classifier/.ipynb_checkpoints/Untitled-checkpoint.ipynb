{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Adi\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:526: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "C:\\Users\\Adi\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:527: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "C:\\Users\\Adi\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:528: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "C:\\Users\\Adi\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:529: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "C:\\Users\\Adi\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:530: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "C:\\Users\\Adi\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:535: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "from matplotlib import pyplot as plt\n",
    "import cv2\n",
    "import random\n",
    "import pickle\n",
    "import tensorflow\n",
    "\n",
    "file_list = []\n",
    "class_list = []\n",
    "\n",
    "DATADIR = \"Data\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "CATEGORIES = [\"Animal\", \"Vehicle\", \"Credit_card\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "IMG_SIZE = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "for category in CATEGORIES :\n",
    "\tpath = os.path.join(DATADIR, category)\n",
    "\tfor img in os.listdir(path):\n",
    "\t\timg_array = cv2.imread(os.path.join(path, img), cv2.IMREAD_GRAYSCALE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_data = []\n",
    "\n",
    "def create_training_data():\n",
    "\tfor category in CATEGORIES :\n",
    "\t\tpath = os.path.join(DATADIR, category)\n",
    "\t\tclass_num = CATEGORIES.index(category)\n",
    "\t\tfor img in os.listdir(path):\n",
    "\t\t\ttry :\n",
    "\t\t\t\timg_array = cv2.imread(os.path.join(path, img), cv2.IMREAD_GRAYSCALE)\n",
    "\t\t\t\tnew_array = cv2.resize(img_array, (IMG_SIZE, IMG_SIZE))\n",
    "\t\t\t\ttraining_data.append([new_array, class_num])\n",
    "\t\t\texcept Exception as e:\n",
    "\t\t\t\tpass\n",
    "\n",
    "create_training_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "random.shuffle(training_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = [] #features\n",
    "y = [] #labels\n",
    "\n",
    "for features, label in training_data:\n",
    "\tX.append(features)\n",
    "\ty.append(label)\n",
    "\n",
    "X = np.array(X).reshape(-1, IMG_SIZE, IMG_SIZE, 1)\n",
    "\n",
    "# Creating the files containing all the information about your model\n",
    "pickle_out = open(\"X.pickle\", \"wb\")\n",
    "pickle.dump(X, pickle_out)\n",
    "pickle_out.close()\n",
    "\n",
    "pickle_out = open(\"y.pickle\", \"wb\")\n",
    "pickle.dump(y, pickle_out)\n",
    "pickle_out.close()\n",
    "\n",
    "pickle_in = open(\"X.pickle\", \"rb\")\n",
    "X = pickle.load(pickle_in)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 573 samples, validate on 64 samples\n",
      "Epoch 1/45\n",
      "573/573 [==============================] - 39s 68ms/sample - loss: 1.4013 - acc: 0.3979 - val_loss: 1.8172 - val_acc: 0.0000e+00\n",
      "Epoch 2/45\n",
      "573/573 [==============================] - 35s 61ms/sample - loss: 0.9074 - acc: 0.5759 - val_loss: 0.7909 - val_acc: 0.6719\n",
      "Epoch 3/45\n",
      "573/573 [==============================] - 35s 61ms/sample - loss: 0.6826 - acc: 0.7138 - val_loss: 0.2390 - val_acc: 0.8906\n",
      "Epoch 4/45\n",
      "573/573 [==============================] - 35s 61ms/sample - loss: 0.5402 - acc: 0.7766 - val_loss: 0.3797 - val_acc: 0.8594\n",
      "Epoch 5/45\n",
      "573/573 [==============================] - 35s 61ms/sample - loss: 0.5074 - acc: 0.7784 - val_loss: 0.6422 - val_acc: 0.8125\n",
      "Epoch 6/45\n",
      "573/573 [==============================] - 35s 61ms/sample - loss: 0.4295 - acc: 0.8237 - val_loss: 0.5886 - val_acc: 0.8125\n",
      "Epoch 7/45\n",
      "573/573 [==============================] - 35s 61ms/sample - loss: 0.3282 - acc: 0.8639 - val_loss: 0.3174 - val_acc: 0.8750\n",
      "Epoch 8/45\n",
      "573/573 [==============================] - 35s 61ms/sample - loss: 0.3656 - acc: 0.8517 - val_loss: 0.5400 - val_acc: 0.8125\n",
      "Epoch 9/45\n",
      "573/573 [==============================] - 35s 61ms/sample - loss: 0.3660 - acc: 0.8464 - val_loss: 0.3697 - val_acc: 0.8906\n",
      "Epoch 10/45\n",
      "573/573 [==============================] - 35s 60ms/sample - loss: 0.2136 - acc: 0.9180 - val_loss: 0.5083 - val_acc: 0.8750\n",
      "Epoch 11/45\n",
      "573/573 [==============================] - 35s 62ms/sample - loss: 0.1565 - acc: 0.9424 - val_loss: 0.5255 - val_acc: 0.9062\n",
      "Epoch 12/45\n",
      "573/573 [==============================] - 35s 60ms/sample - loss: 0.2163 - acc: 0.9075 - val_loss: 0.4607 - val_acc: 0.9219\n",
      "Epoch 13/45\n",
      "573/573 [==============================] - 35s 61ms/sample - loss: 0.1479 - acc: 0.9442 - val_loss: 0.5437 - val_acc: 0.8906\n",
      "Epoch 14/45\n",
      "573/573 [==============================] - 35s 61ms/sample - loss: 0.1002 - acc: 0.9634 - val_loss: 0.6621 - val_acc: 0.8906\n",
      "Epoch 15/45\n",
      "573/573 [==============================] - 35s 62ms/sample - loss: 0.0821 - acc: 0.9773 - val_loss: 0.6951 - val_acc: 0.8750\n",
      "Epoch 16/45\n",
      "573/573 [==============================] - 36s 62ms/sample - loss: 0.0593 - acc: 0.9825 - val_loss: 0.6390 - val_acc: 0.8906\n",
      "Epoch 17/45\n",
      "573/573 [==============================] - 35s 61ms/sample - loss: 0.0935 - acc: 0.9564 - val_loss: 0.7918 - val_acc: 0.8594\n",
      "Epoch 18/45\n",
      "573/573 [==============================] - 35s 61ms/sample - loss: 0.0690 - acc: 0.9791 - val_loss: 0.5603 - val_acc: 0.9219\n",
      "Epoch 19/45\n",
      "573/573 [==============================] - 35s 61ms/sample - loss: 0.0382 - acc: 0.9860 - val_loss: 0.7144 - val_acc: 0.8906\n",
      "Epoch 20/45\n",
      "573/573 [==============================] - 35s 61ms/sample - loss: 0.0527 - acc: 0.9808 - val_loss: 0.5209 - val_acc: 0.9375\n",
      "Epoch 21/45\n",
      "573/573 [==============================] - 35s 62ms/sample - loss: 0.0355 - acc: 0.9913 - val_loss: 0.6949 - val_acc: 0.9219\n",
      "Epoch 22/45\n",
      "573/573 [==============================] - 35s 62ms/sample - loss: 0.0161 - acc: 0.9965 - val_loss: 0.8261 - val_acc: 0.8906\n",
      "Epoch 23/45\n",
      "573/573 [==============================] - 35s 61ms/sample - loss: 0.0080 - acc: 0.9983 - val_loss: 0.9352 - val_acc: 0.8906\n",
      "Epoch 24/45\n",
      "573/573 [==============================] - 35s 61ms/sample - loss: 0.0057 - acc: 1.0000 - val_loss: 0.9741 - val_acc: 0.8906\n",
      "Epoch 25/45\n",
      "573/573 [==============================] - 35s 62ms/sample - loss: 0.0119 - acc: 0.9965 - val_loss: 0.9517 - val_acc: 0.8906\n",
      "Epoch 26/45\n",
      "573/573 [==============================] - 36s 63ms/sample - loss: 0.0119 - acc: 0.9965 - val_loss: 0.8774 - val_acc: 0.9062\n",
      "Epoch 27/45\n",
      "573/573 [==============================] - 36s 62ms/sample - loss: 0.0055 - acc: 1.0000 - val_loss: 0.8642 - val_acc: 0.9219\n",
      "Epoch 28/45\n",
      "573/573 [==============================] - 35s 62ms/sample - loss: 0.0072 - acc: 0.9983 - val_loss: 0.9284 - val_acc: 0.9219\n",
      "Epoch 29/45\n",
      "573/573 [==============================] - 35s 61ms/sample - loss: 0.0105 - acc: 0.9965 - val_loss: 0.9929 - val_acc: 0.9062\n",
      "Epoch 30/45\n",
      "573/573 [==============================] - 35s 62ms/sample - loss: 0.0400 - acc: 0.9878 - val_loss: 0.8670 - val_acc: 0.9219\n",
      "Epoch 31/45\n",
      "573/573 [==============================] - 35s 61ms/sample - loss: 0.0207 - acc: 0.9948 - val_loss: 0.8658 - val_acc: 0.9062\n",
      "Epoch 32/45\n",
      "573/573 [==============================] - 35s 61ms/sample - loss: 0.0208 - acc: 0.9930 - val_loss: 0.9309 - val_acc: 0.9219\n",
      "Epoch 33/45\n",
      "573/573 [==============================] - 35s 62ms/sample - loss: 0.0122 - acc: 0.9983 - val_loss: 0.8724 - val_acc: 0.9219\n",
      "Epoch 34/45\n",
      "573/573 [==============================] - 35s 62ms/sample - loss: 0.0034 - acc: 1.0000 - val_loss: 0.9078 - val_acc: 0.9219\n",
      "Epoch 35/45\n",
      "573/573 [==============================] - 36s 63ms/sample - loss: 0.0041 - acc: 1.0000 - val_loss: 0.9233 - val_acc: 0.9219\n",
      "Epoch 36/45\n",
      "573/573 [==============================] - 40s 69ms/sample - loss: 0.0012 - acc: 1.0000 - val_loss: 0.9234 - val_acc: 0.9375\n",
      "Epoch 37/45\n",
      "573/573 [==============================] - 36s 63ms/sample - loss: 7.2018e-04 - acc: 1.0000 - val_loss: 0.9159 - val_acc: 0.9375\n",
      "Epoch 38/45\n",
      "573/573 [==============================] - 39s 68ms/sample - loss: 5.7305e-04 - acc: 1.0000 - val_loss: 0.9365 - val_acc: 0.9219\n",
      "Epoch 39/45\n",
      "573/573 [==============================] - 36s 63ms/sample - loss: 4.6644e-04 - acc: 1.0000 - val_loss: 0.9265 - val_acc: 0.9375\n",
      "Epoch 40/45\n",
      "573/573 [==============================] - 37s 64ms/sample - loss: 4.2091e-04 - acc: 1.0000 - val_loss: 0.9582 - val_acc: 0.9062\n",
      "Epoch 41/45\n",
      "573/573 [==============================] - 38s 67ms/sample - loss: 2.9772e-04 - acc: 1.0000 - val_loss: 0.9511 - val_acc: 0.9062\n",
      "Epoch 42/45\n",
      "573/573 [==============================] - 37s 65ms/sample - loss: 4.3293e-04 - acc: 1.0000 - val_loss: 0.9503 - val_acc: 0.9219\n",
      "Epoch 43/45\n",
      "573/573 [==============================] - 37s 64ms/sample - loss: 4.3330e-04 - acc: 1.0000 - val_loss: 0.9376 - val_acc: 0.9219\n",
      "Epoch 44/45\n",
      "573/573 [==============================] - 37s 65ms/sample - loss: 8.1518e-04 - acc: 1.0000 - val_loss: 0.9388 - val_acc: 0.9219\n",
      "Epoch 45/45\n",
      "573/573 [==============================] - 35s 62ms/sample - loss: 5.2593e-04 - acc: 1.0000 - val_loss: 1.0153 - val_acc: 0.9062\n",
      "Saved model to disk\n",
      "dict_keys(['loss', 'acc', 'val_loss', 'val_acc'])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x14500ab5a90>"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYUAAAEWCAYAAACJ0YulAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4zLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvnQurowAAIABJREFUeJzt3Xl4VOXZ+PHvnX2HkIQtIJuggGwaKNYN1x/uVixuaKVWWpdabW21m1pf+762r7WtrUtdcKuoiBuvRa0ragUEFDWAyC5hywbZk0ky9++P5yROkkkyQCYJmftzXbkyc7a550DOfZ7lPI+oKsYYYwxAVFcHYIwxpvuwpGCMMaaRJQVjjDGNLCkYY4xpZEnBGGNMI0sKxhhjGllSMBFFRB4XkTtD3HaLiJwS7piM6U4sKRhjjGlkScGYg5CIxHR1DKZnsqRguh2v2ubnIvK5iFSIyKMi0k9EXhORMhF5S0TSA7Y/R0RWi8heEXlPREYHrJskIp94+z0HJDT7rLNEZJW370ciMj7EGM8UkU9FpFREtonI7c3WH+sdb6+3/gpveaKI/ElEtopIiYh86C2bJiJ5Qc7DKd7r20VkgYj8U0RKgStEZIqILPE+Y6eI/F1E4gL2Hysib4pIsYjsFpFfiUh/EakUkYyA7Y4SkQIRiQ3lu5uezZKC6a5mAKcCo4CzgdeAXwGZuP+31wOIyCjgGeAGIAtYBPyfiMR5F8iXgaeAPsDz3nHx9j0SmAv8EMgA/gEsFJH4EOKrAC4HegNnAleLyHnecQ/x4v2bF9NEYJW3393AUcC3vZh+AfhDPCfnAgu8z3waqAdu9M7J0cDJwDVeDKnAW8DrwEDgUOBtVd0FvAfMDDjuLOBZVa0NMQ7Tg1lSMN3V31R1t6puBz4Alqnqp6paA7wETPK2uxD4l6q+6V3U7gYScRfdqUAs8BdVrVXVBcDygM+4CviHqi5T1XpVfQKo8fZrk6q+p6pfqKpfVT/HJaYTvNWXAm+p6jPe5xap6ioRiQK+D/xEVbd7n/mR951CsURVX/Y+s0pVV6rqUlWtU9UtuKTWEMNZwC5V/ZOqVqtqmaou89Y9gUsEiEg0cDEucRpjScF0W7sDXlcFeZ/ivR4IbG1Yoap+YBuQ7a3brk1Hfdwa8HoI8DOv+mWviOwFBnv7tUlEviUi73rVLiXAj3B37HjH2Bhkt0xc9VWwdaHY1iyGUSLyqojs8qqU/juEGABeAcaIyHBcaaxEVT/ez5hMD2NJwRzsduAu7gCIiOAuiNuBnUC2t6zBIQGvtwG/V9XeAT9JqvpMCJ87D1gIDFbVXsCDQMPnbANGBNmnEKhuZV0FkBTwPaJxVU+Bmg9p/ADwJTBSVdNw1WvtxYCqVgPzcSWay7BSgglgScEc7OYDZ4rIyV5D6c9wVUAfAUuAOuB6EYkRkfOBKQH7Pgz8yLvrFxFJ9hqQU0P43FSgWFWrRWQKcEnAuqeBU0Rkpve5GSIy0SvFzAXuEZGBIhItIkd7bRhfAQne58cCvwHaa9tIBUqBchE5HLg6YN2rQH8RuUFE4kUkVUS+FbD+SeAK4BzgnyF8XxMhLCmYg5qqrsPVj/8Ndyd+NnC2qvpU1Qecj7v47cG1P7wYsO8KXLvC3731G7xtQ3ENcIeIlAG34pJTw3G/Bs7AJahiXCPzBG/1TcAXuLaNYuAPQJSqlnjHfARXyqkAmvRGCuImXDIqwyW45wJiKMNVDZ0N7ALWAycGrP8ProH7E689whgAxCbZMSYyicg7wDxVfaSrYzHdhyUFYyKQiEwG3sS1iZR1dTym+7DqI2MijIg8gXuG4QZLCKY5KykYY4xpZCUFY4wxjQ66QbUyMzN16NChXR2GMcYcVFauXFmoqs2ffWnhoEsKQ4cOZcWKFV0dhjHGHFREZGv7W1n1kTHGmACWFIwxxjSypGCMMabRQdemEExtbS15eXlUV1d3dSg9QkJCAoMGDSI21uZcMSbS9IikkJeXR2pqKkOHDqXpgJhmX6kqRUVF5OXlMWzYsK4OxxjTycJWfSQic0UkX0RyW1kvInKviGwQN+3ikfv7WdXV1WRkZFhC6AAiQkZGhpW6jIlQ4WxTeByY3sb604GR3s8c3Njw+80SQsexc2lM5Apb9ZGqvi8iQ9vY5FzgSW9WrKUi0ltEBqjqznDFZExHq633U1lTT7mvjoqahp96yr3Xlb46ymvqqa33k5ESR9/UBPqlxdMvLYGM5DhiokO7LyuvqSO/tJrdpTXkl1WTX1pDVW09SXHRpMTHkBQfQ0p8NMlxMSTHN/y4dYmx0V2S6Gvr/WzfU0VJVS0VNXXunHjno7KmjgpfPdgwO/vk5NH9mDC4d1g/oyvbFLJpOr1gnresRVIQkTm40gSHHHJI89Vdbu/evcybN49rrrlmn/Y744wzmDdvHr17h/cf2eyfvZU+NhVWsKmggs2F5WwurGBrUSWl1bWNF35fnX+/jy8CmSnx9EmKo7Vrdk2dn/zSancBPYDPcckimuT4GA7pk8TU4RlMHZ7BEQPT2kxMVb561uwsYfWOUnx1flK8hJMSH0NSnDteUlw0u0tr2FRYzuaCCjYXVrCpsIKviyup97d90bdC6b7pm5bQo5NCsP8OQf8HqepDwEMAOTk53e7WYu/evdx///0tkkJ9fT3R0dGt7rdo0aJwh2ZCpKqs213G22vzWfxVAet3l7GnsrZxfUyUcEifJIZkJDGqX2rjBTYlLuAuveEOPe6bu/SkOHcBjYkWisp97C6tJr+spvF3fmk1xRW+VuOKi4nixMP60jctnn5p8Y0ljazUBJLjoqnw1VPplVLKa+q/Ka34mr33XpfX1LFudxl3vfYlAMlx0eQM7cPU4Rl8a3gf/H7li+0lfLG9hNztJWzIL6ed63oT8TFRDMtMZvSAVM4Y15+hGcn0SY5rTCTu/LhzlRgbTVSUZYXupiuTQh5uLt0Gg3Dz7R50brnlFjZu3MjEiROJjY0lJSWFAQMGsGrVKtasWcN5553Htm3bqK6u5ic/+Qlz5swBvhmyo7y8nNNPP51jjz2Wjz76iOzsbF555RUSExO7+Jt1nnq/EiUH1p6hquwurWm8qK3ZUUpiXDTDMpMZnpnM8KxkhmUmk5rgutrW1NWzdFMxb6/dzdtr89m+twqAcdm9mH7EgCb7DO6TRGyIVT2t6d8rgf69Eg7oGM31SoyiV+K+dx0uKKth2eYilm4qYtmmYv7w+pdN1melxjeeh3HZvTgiO42kuJgmVWINSabSV0dmSjzDs1IYkJZgF/qDXFcmhYXAdSLyLPAtoKQj2hN+93+rWbOj9ICDCzRmYBq3nT221fV33XUXubm5rFq1ivfee48zzzyT3Nzcxi6dc+fOpU+fPlRVVTF58mRmzJhBRkZGk2OsX7+eZ555hocffpiZM2fywgsvMGvWrA79Hl1NVSmq8LnqhYJyNhVWsLnAq2ooqmRQeiL3XjyJI7J7hXzMlVuLWbyuwEsEpRSW1wAQJTA8K4Waunpe/XxHk6rrrNR4BqUnsm5XGZW+ehJiozj20Cx+fNKhnHR4X/qmdeyFuzvKSo3nrPEDOWv8QMAliRVbiomJjmL8oF70a+Uc7E8CMgeXsCUFEXkGmAZkikgecBsQC6CqDwKLcPPYbgAqgdnhiqWzTZkypUkf/3vvvZeXXnoJgG3btrF+/foWSWHYsGFMnDgRgKOOOootW7Z0WrzhVlJZy4uf5vHMx1/z1e7yxuVx0VEMyUhieGYyJx3el4WrdnD+/R/x27NGM2vqkDZLDSWVtfx+0Rrmr8gjSmBk31ROGJXFuOw0xg3qxegB7s4WoLq2nm3FlU3aB7YWVfKdSdmcMrofR4/IICG29Wq+SJCVGs/p4wZ0dRimGwhn76OL21mvwLUd/blt3dF3luTk5MbX7733Hm+99RZLliwhKSmJadOmBX0GID4+vvF1dHQ0VVVVnRJruKgqK7fuYd6yr/nXFzupqfMzYXBvfnPmaA7tm8LwzBSy0xOJDqhq+NEJI/jZ/FX89pXVLNlUxF0zxpOW0PLO9PXcnfz2ldUUV/i4etoIrjvxUJLjW/+vnBAbzch+qYzslxqW72pMT9IjnmjuaqmpqZSVBZ/VsKSkhPT0dJKSkvjyyy9ZunRpJ0fXucqqa3l+hSsVrM8vJyU+hu/mDOLiKYcwdmDb1UJ9kuN49HuTeeiDTfzvG+vI3f4h911yJOMGuf3yy6q57ZXVvJa7izED0njsisn7VNVkjGmfJYUOkJGRwTHHHMMRRxxBYmIi/fr1a1w3ffp0HnzwQcaPH89hhx3G1KlTuzDS8PHV+Zm3bCv3vrOB4gofEwf35o8zxnPWhAGN1TihiIoSfnTCCCYPTefH8z5lxgMf8eszR5MUF82d/1pLVW09v5h+GFcdN/yAG36NMS0ddHM05+TkaPNJdtauXcvo0aO7KKKeKdRzqqos+mIXf3zjS7YWVfLtERncPP3wDulLvafCx8+e/4x3vswHYPLQdO6aMZ4RWSkHfGxjIo2IrFTVnPa2s5KC2W/LtxTz+3+tZdW2vRzWL5XHZk9m2qisDnt6Nj05jkcuz2Hex18TEyXMzBls3R2NCTNLChGu3q9NGntDsbOkiltfWc2ba3bTLy2eP84Yz4yjBu3zcUIRFSXMmjqkw49rjAnOkkKEqvcrO/ZWsbfSx8DeiWSkxLe/E5BfWs3FDy0lv6yGm04bxZXHDicx7iDszlm1B+LTIOogjD2SqcKezeBvZdiP+DRI7Rd8XWvqfFBXBQnWaQEsKUSkipo6tu2ppLbOT3xsdOOTvO0lhj0VPmY9uoz8shqeuvJbHDUkvTPC7Xi7cuHRUyE5C6ZeA5MuhXjrrtqt1dXAF8/Dkvsgf03b246aDkdfB0OPbXtwpYoiWPEofPww1NfAxc/CkG93bNwHIUsKEcSvSn5pNQVlNcTGRDE8K4XEuGi+LqpsNzGUVtdy+dyP2VpUyWOzJx+8CaGmHJ6/wiWB1AHw+s3w7n9DzhUw5YfQK7urIzSBKopgxVz4+CGoyIe+Y+GMuyGxlf9/Bevchf6Js2DABJccxn4HogOedyn4CpbeD589A3XVcOipsGcLPHkezHgExpzTKV+tu7KkECEanuqtqq2nT1IcA3p/8+DYIRlJwRNDfR1Ex1Dpq2P2Y8v5clcpD12Ww7dHZHbV12jJ74eoELumqsK/fgrFG+HyhTDsOMhbAUv+Dh/9zd2Fjv2Ou5AMnBjeuA+UKlSXtL4+LgWiO+nPu64Gajv4YcuynS4RrHrGVe0ceiocfS0Mn9b+0KrH/RQ+f879e754Fbx5G3xrDvQf50oFX70O0fEw4SJXUux7OFQWw7wLYf7lcMb/wpSrDiz++jrwlbe/XXMirgqsC4ePtS6pXSAlJYXy8nJ27NjB9ddfz4IFC1psM23aNO6++25yclrvQfaXv/yFOXPmkJSUBAQfirthvKFdJdVEiZCdnhh0/Bq/Kl97w0IPTalj+/rVjH7jQnzn3Mfsj7NZsrGIv19yJGd0p6EQ6nzwyMmQlAEzn2i/TviTp2DhdTDtVzDt5qbr9mx1F6GVT4CvzCWGU/8r9ITTWXyV8PmzsOR+KFrf+nbJWTD5Kph8JSS3k8TLdsPyh2H5o5DY210oJ14Ccclt71e4wd1xr5rnLtwdLToeJlwIU691F+595ffDxrdd0t/0nluWlOku+DlXQkpW0+19lfDClbBuERz7Uzj51n2/OJfthuWPuJ+q4n2PGWDARK+Ec17TEs4BCrVLqiWFLtCQFNoSSlJoGGU1M7P1P/qSqlq2FlWQmhDLoPTE1h/48tejlcXUluUTpz5Wf13E6FW/g11f8Lvay5kw4xecf+SgkL5fp1n6oKv+kSjIGg2zFkDawODb5q+Fh06EwZPhspdbb2CuLoG373B/1EfMgPMegJjQGuHDqvnFZsBEr1okLsjGCpsWw/o3ICYBxl/o7rKzDmu62a5cd1H/4nmor4XDToeKAshbDgm9IWc2TJnT9Jyqwtb/wEd/9+64Y2H8TFet05Fi4mH0OS0v3Ptr1xdQvAlG/j+IbWPAw/o6WHQTrHwMJlwM5/wttAvz7jWuZPLFfO9cngFDjyH4DAFtqK2Az55zCT8tG771Qzjyey5ZHyB7TqET3XzzzQwZMqRxPoXbb78dEeH9999nz5491NbWcuedd3Luuec22W/Lli2cddZZ5ObmUlVVxezZs1mzZg2jR49uMvbR1VdfzfLly6mqquKCCy7gd7/7Hffeey87duzgxBNPJDMzk3fffbdJkrjnnnuYO3cuvjo/My65nP/+7c1s3bq15RDdLy4g0V8OFYWI1hMbm0iBDmCn389vfbfxw/r/4XexT0BRb/Df3n3unKv2wOK7XHXCMTfAc5fBI6fCrBda3lX6KmD+91w7wvmPtN3jKKGXq7PuNRjeug3K8+Gip7uuZ8ru1a5UEHixOfpa1yDa1l3s0de6+vWl98Nnz8InT8DI09zy+jpY8jd39xyb5C46U6+GjBFu320fu+q0//zV/T7iAndxKtrg7rp3fuZKZyf8Aib/AFL6dsqpOCD9x7mf9kTHwFl/donw3d+7f/+ZTwTviKDqlUTug43vQEwiHHm5K2k1nMv9cezPYMOb7ty/eSu89wc48jL41o+gz7D29z9APa+k8Not7q6gI/UfB6ff1erqTz/9lBtuuIHFixcDMGbMGF5//XV69+5NWloahYWFTJ06lfXr1yMijSWFwKRwzz33kJuby9y5c/n888858sgjWbp0KTk5ORQXF9OnTx/q6+s5+eSTuffeexk/fnyLkkLD+61bt3LFFVfw73c/YGtROVecdxrPzHua9PR0Dj30UFasWMHEiROZOeM8zpk2mVkzzoD4Xu6POy4ZP/DRis+Y9cJ2fnvGKK4sfcA13o2bCefeBzHB7k472Ru/dn+MP/rA/fvs/ByevsA1HF78HAw5+pttX7raNSpe/rJLIqH67Fl45VrIOhwuXQBpnVR11vxiE5sEEy9teuHeFxWFrmpo+cOuJACukX3KHDjqCkjqE3y/4s2w7B/wyZPuDhYgc5S76E24CGJ7+HwfnzwJ/3eDex3sRkIV/LWQ0t+1WRw1u/Vzub92fuZuCnIXgPrdDcvkK/frUFZS6ESTJk0iPz+fHTt2UFBQQHp6OgMGDODGG2/k/fffJyoqiu3bt7N792769+8f9Bjvv/8+119/PQDjx49n/Pjxjevmz5/PQw89RF1dHTt37mTNmjVN1jf34Ycfct5551Hhj6F3WhoXzDifDz74gHPOOccN0T1hApTt4qjDh7BlR6GregkoUkfhBqf7943HM6pfKuif3J3TO//leoBc+M+u7cJZvMldrCbN+ubub8B4uPJN+OcMePLcb3qRrJoHn82DE27et4QA7sKX0teVQh71SiHNq2A6Um21KxEsuR8K1rqLzUm/hZzvH9jFJjnTtaEc8xNY8zJExbiqmfaSe59h7mZo2i2Q+4IrPR16SvcpLYbbkZdDn+Gw4a3Wt8ka7arxwnWjNGACnP8POOU210g+9NjwfE6AnpcU2rijD6cLLriABQsWsGvXLi666CKefvppCgoKWLlyJbGxsQwdOjTokNmBgg0PsXnzZu6++26WL19Oeno6V1xxRbvHUVV89X4qfXVk905sctz4+HgoyYPKQqLjk6mqjw1axyoiLiG4N3D8Te7ucuGP4bEz3J3zvj4k1FHeut3VpZ/0m6bL04fA99+AZ7xeJMfeCMsehKHHuaSwP0acBLMXwT8vgEdPg0ueg0M6eFDD5nfy/Y6A8x50bRodebGJTXCJbl8l9t7vu9OD3tBjO+VC3K60gS4xdIKelxQ6WmWRa3zsdUibXfwuuugirrrqKgoLC1m8eDHz58+nb9++xMbG8u6777J169Y2P+b444/n6aef5sQTTyQ3N5fPP/8cgNLSUpKTk+nVqxe7d+/mtddeY9q0acA3Q3Znpvd2d8/+eqir4fjjj+eSWZdz4ZU/Jo4YXnrpJZ566inXG6PeB5WF7g44MR0qKkI/F5MuhZR+7oL7tyNbr2dPznIXkXEz227UA1cE3/QeLH3AXQDPe6DtUsjWJbDmFdeDKDVIqSs5w3U3feFK+PAe19vk/IcP7MnlARPgB2/CU+fD42d1fB16RYH7d2mo8x92gs1ob7qMJYX2VBa7/sa1X7n63FZ6oowdO5aysjKys7MZMGAAl156KWeffTY5OTlMnDiRww9vu0vd1VdfzezZsxk/fjwTJ05kypQpAEyYMIFJkyYxduxYhg8fzjHHHNO4z5w5czj99NMZ0DeDd5/9O2g9FK5j/CFDOP+CC7j07JOJjhJ+8IMfMGn8OLaset/VS6Zluwvb/lx4Rp4C33/NPVDkrwu+zY7PXIni7Tta7xZZV+OqJJbcB7tzXSKpLIbHz4RLng9eCvH74d+/htSB8O3rWo8xLglmPuUaWYcc0zFtAelDXfXUB3+CmjaeD9gfCb1h0mX71+3SmA7W8xqaO9quXNclra7GXUT7jHAXne5C/a6HSmwi9D4EKgqpLy8gGj8am4Sk9HUNlcUbXb/+9CGtPw0a4IDOqSpsft9d8Bu6RTY8KJSc9c3QAuW7XVfGo6+FcRe4feZf7raZ9SJkHtr0uF8scCWA8x5w/eiNMSGzhuaO4K9zvQuSsyAhDYo2uv7DfYaHp6FV1dX3J6SF3gWyao+LM7kvRMdREd+XzaWJDEmsJrVuj3t8H0CiXUmnMxqIRWD4Ce4ncEiBlY+7B5Lqa1yD5dEPwvATvymxjDwVrngVnp4Jc0+DS+bDIO//cG2Va0voPx7G70e9uDEmJBHSjWA/1dW43zEJ7k48c5Rr4Cza6Ko6OlpVsavv3/t166NABlJ1/ahjEhov9vllNURFRZOU3h/6job04ZDYBzJHdk2PoaxRcPZf4MbVcOJvXBfIa5a6njwjTmpZhZV9FFz5bxfr42fButfd8qUPQMk2+H+/j5zeL8Z0gR5TUlDVDpvcpVGd18sn1mtHiIlzF9fizbB3q1eK2M+6+eb89WjpTuoljhi/D3/ZLqLaG5ytpszF2PsQEKHSV0dZdS390xK+mdsgsZf72QdhqVJMzoQTfh7athkjXP39vJnw7CWu18UH97gHt4Yd3/GxGWMa9YhbroSEBIqKijr+YlZbDYir8mgQFePaFRJ6Q+kON3BXR6goQPy1bKnPYI+mQHkBeQV72Vvpo97fyveqyHfxeG0E+aU1REcJGSn7341RVSkqKiIhoZ1eQ+GW0he+96p7tuDNW93YOqfe0bUxGRMBekRJYdCgQeTl5VFQUNCxB64ocNU4JV+2XKcKVZXg+wKSd7rG3P3lr0dLd1BNHNWxUVTGCTsr8qmmhLWaSpRAQmw0iXHRxEdHuSkp62tdQkroBXvWUVvvZ3dpDWmJMXxVcmCDaCUkJDBoUDcY5yg+xT0X8PbvXI+pzJFdHZExPV6PSAqxsbEMGxaGMUH+erF7Unbmk8HX1/ngselutMgfLt7vcUl2PfUD+mx4kV8OfJS7fnC8G7Tu7Zfhgz+x+oyXeGZHFou+2EVxhQ+A3kmx3B33MMfXLObJqf9i4MDeLFiZx/LNxXx4y0lBR0E9aEXHwml3dnUUxkSMHpEUwqK22rUbjPtu69vExMEFj8E/joMFs93TtPs4ouam3KUM3bCAlxLO5fbvnfXNKKbH3gifPMnY3D9y5+zXuO3ssSzbVMyXu0rJ37mNE9a8y8Kok7jz3XwgH4DrTjy0ZyUEY0yns6TQmuKN7hmA9sa6SR8C594Pz13qJvPYh2E2du2tovCFn5MhyRzz/btITQi4oMenwom/hldvgLULiR1zLseOzOTYkZnwzjNAHTOu/R+mpwxhc2EFO0uqOW5kN5r8xhhzUOoRDc1hUbDO/c4c1f62o89yw9ouewDWvhrS4cuqa7n/kQeYop9T9e2f079fkKduJ13mBtx68zZXVQVuIpDlj7ieOBkjSI6P4YjsXpw6ph8JsTYJvTHmwFhSaE3hV4CE3rh56h1u4pNXrnGzeLWhtt7Pj59ewWVlj1CZOpT+J10TfMPoGFefvmezGywN3KxbVcXuKWBjjOlglhRaU7DO9f8Pdcz4mHj47uOuV9KC739zZ9+MqnLrK7kM2vQcI2U7SWf+d9sjYY48BUacDIv/6CYxX3IfDJzkJlkxxpgOZkmhNYVf7fvY+X2Guen7tq9w3SiDeG75Nv7v43X8MvFlGHKsqwZqz2l3Qk0p/PN8N/vV0dfZKJrGmLCwhuZg/PVQuH7fJ2UBN9n2lqvctIUx8W7aQs/Okmo2/Wczc9O3kFy1B/7fnaFd3PuNce0LnzwBaYNgzLnt72OMMfshrElBRKYDfwWigUdU9a5m6w8BngB6e9vcoqqLwhlTSPZudYO27e8sW6fd6aYE/eBPTRYPAH4VDVQBU37oqoFCdeKv4ct/wXE3hjaRuDHG7IewJQURiQbuA04F8oDlIrJQVdcEbPYbYL6qPiAiY4BFwNBwxRSygq/c78z9TAqxCTD7NfCVAeD3K9c/+yn/2VjEY7MnM3FQuhsJdV+k9oOb1ttgcMaYsArnFWYKsEFVN6mqD3gWaF7voUDD1bEXsCOM8YSu0OuOmhVCd9TWREW5ISgSevHAskJe/aqSG87MYeKhQ/Y9IQQe0xhjwiicV5lsYFvA+zxvWaDbgVkikocrJfw42IFEZI6IrBCRFR0+vlEwBV+50U9DmIymPf/ZUMif/r2OsycM5PKjh3RAcMYYEz7hTArBWlCbD/d5MfC4qg4CzgCeEpEWManqQ6qao6o5WVlZYQi1mcJ1+9+eEGBXSTXXP/Mpw7NSuOv8cR0/tLcxxnSwcCaFPGBwwPtBtKweuhKYD6CqS4AEoGvHalB1JYVQnmRuQ229n2vnfUJVbT0PzjqS5Hjr6GWM6f7CeaVaDowUkWHAduAioPnEul8DJwOPi8hoXFLohPqhNpTvdhOzh1BSyC+tZvFXBVTU1FHhq6e8po7KmjrKa+rZWlTByq17+NvFkzi0bxfMeGaMMfshbElBVetE5DrgDVx307mqulpE7gBWqOpC4GfAwyJyI65q6QoNy7Rf+yDEMY98dX4ufGifrZdZAAAVYElEQVQpmwsrGpfFRAnJ8TGkxMeQHB/NL6YfxtkTBoYzWmOM6VBhrdPwnjlY1GzZrQGv1wDHhDOGfVbodUdtp6Tw9LKtbC6s4K8XTeS4kVkkx0cTFx1l7QbGmIOaVXQ3V7AO4lIhNciopZ6Sqlr++vZ6jjk0g3MmDLREYIzpMazje3OF69zzCW1c6O97dwMlVbX86ozRlhCMMT2KJYXmCr5q80nmbcWVPP6fLcw4chBjB/bqxMCMMSb8LCkEqi6B8l1tPsn8h9e/JCoKbjrtwJ9jMMaY7saSQqB2xjz65Os9vPr5TuYcN5z+vRI6MTBjjOkclhQCNY551DIpqCq//9daMlPi+eEJIzo5MGOM6RyWFAIVrIPoOOjdcoyi13J3sXLrHn522ih7OtkY02NZUghUuB76jHBzIwfw1fm567UvOaxfKjNzBreyszHGHPwsKQRq6I7azJNLtvB1cSW/OnM00VHWBdUY03NZUmhQWw17trRoZN5b6eNv72zguJGZnDCqE0ZoNcaYLmRJoUHxRlB/i0bmhz/YRFl1Lb8+c3QXBWaMMZ3HkkKDVgbCe3ttPkePyODw/vs5W5oxxhxELCk0KPwKEMgc2bioqLyGL3eV8e0RXTvFgzHGdBZLCg0K1kHvQyA2sXHRss3FAEwdntFVURljTKeypNCg8KsW7QlLNhaRFBfN+EE2xpExJjJYUgDw17tnFJq1JyzZVMTkoX2IjbbTZIyJDHa1A9i7FeprmpQU8suq2ZBfztEjrOrIGBM5LClA0IHwlm5y7QlHW3uCMSaCWFKAgIHwvqk+WrKxiNT4GMYOtK6oxpjIYUkBoHSHm4IzMb1x0dJNRUwZ1ocYa08wxkQQu+IB1JRDwjclgl0l1WwurLD2BGNMxLGkAOArg7iUxrdLNhUC9nyCMSbyWFIAqCmD+ICksLGIXomxjBlg7QnGmMhiSQFc9VF8auPbJZuK+NawPkTZMNnGmAhjSQHAV95YfZS3p5JtxVXWnmCMiUiWFMCrPnIlhSUbiwAsKRhjIpIlBWiaFDYV0Sc5jlF9U9vZyRhjeh5LCqqN1UeqytKNRUwdbu0JxpjIZEmhrhr8dRCfwtfFlewoqbahLYwxEcuSQk25+x2fZu0JxpiIF9akICLTRWSdiGwQkVta2WamiKwRkdUiMi+c8QTlK3O/41JYsqmIrNR4RmSltL2PMcb0UDHhOrCIRAP3AacCecByEVmoqmsCthkJ/BI4RlX3iEjfcMXTqhqXFDQumSUbi5g6PAMRa08wxkSmcJYUpgAbVHWTqvqAZ4Fzm21zFXCfqu4BUNX8MMYTnFd9tLM6lvyyGmtPMMZEtJCSgoi8ICJnisi+JJFsYFvA+zxvWaBRwCgR+Y+ILBWR6a18/hwRWSEiKwoKCvYhhBD4XFL4vKAesPYEY0xkC/Ui/wBwCbBeRO4SkcND2CdYHYw2ex8DjASmARcDj4hI7xY7qT6kqjmqmpOVlRViyCHyqo+W76ilf1oCQzOSOvb4xhhzEAkpKajqW6p6KXAksAV4U0Q+EpHZIhLbym55wOCA94OAHUG2eUVVa1V1M7AOlyQ6j5cUPsrzcfQIa08wxkS2kKuDRCQDuAL4AfAp8FdcknizlV2WAyNFZJiIxAEXAQubbfMycKJ3/ExcddKmfYj/wHnVR9sqoqw9wRgT8ULqfSQiLwKHA08BZ6vqTm/VcyKyItg+qlonItcBbwDRwFxVXS0idwArVHWht+40EVkD1AM/V9WiA/tK+8grKVSQYO0JxpiIF2qX1L+r6jvBVqhqTms7qeoiYFGzZbcGvFbgp95P16gppzoqkX5pSQzuY+0JxpjIFmr10ejABmARSReRa8IUU+fylVGuiRyR3aurIzHGmC4XalK4SlX3Nrzxniu4Kjwhda66qlJK6+M5IttmWTPGmFCTQpQEdMvxnlaOC09InauidC9lJHLEQCspGGNMqG0KbwDzReRB3LMGPwJeD1tUnai6ooQKTWDcIEsKxhgTalK4GfghcDXuobR/A4+EK6jOVF9VSm1MH/qmxnd1KMYY0+VCSgqq6sc91fxAeMPpfFJbTmzSUHtozRhjCP05hZHA/wBjgISG5ao6PExxdYrq2nri6itJSmkxsoYxxkSkUBuaH8OVEupwTyA/iXuQ7aD25a4yUqgirVd6V4dijDHdQqhJIVFV3wZEVbeq6u3ASeELq3Os2VZIvNSRkWFPMhtjDITe0FztDZu93hu6YjvQ+RPidLAN29xoHVZSMMYYJ9SSwg1AEnA9cBQwC/heuILqLFt37gJA4lO7OBJjjOke2i0peA+qzVTVnwPlwOywR9UJfHV+dhcUQixgScEYY4AQSgqqWg8cJT2sz+ZXu8uI91e5N3EpXRuMMcZ0E6G2KXwKvCIizwMVDQtV9cWwRNUJcreXkCpeUrCSgjHGAKEnhT5AEU17HClw8CaFHSVkxvncG0sKxhgDhP5Ec49oRwj0xfZSzuglUIJVHxljjCfUJ5ofw5UMmlDV73d4RJ2gtt7P2p2lXDes3iWFeEsKxhgDoVcfvRrwOgH4DrCj48PpHBsLyvHV+RmU7HcL4qz6yBhjIPTqoxcC34vIM8BbYYmoE3yRVwLAgIQ6iEmE6FBzozHG9GyhPrzW3EjgkI4MpDOt3lFKclw0vaKqrerIGGMChNqmUEbTNoVduDkWDkq520sYMzAN8ZVbzyNjjAkQavVRj7ly1vuV1TtKuWjKYCgrt55HxhgTIKTqIxH5joj0CnjfW0TOC19Y4bO5sJyq2no3J3NNmZUUjDEmQKhtCrepaknDG1XdC9wWnpDCK3d7KQBHZFtSMMaY5kJNCsG2Oyi77HyxvYSE2ChGZCWDz6qPjDEmUKhJYYWI3CMiI0RkuIj8GVgZzsDCJXd7CaMHpBETHeWVFCwpGGNMg1CTwo8BH/AcMB+oAq4NV1Dh4vcra3aUuvYEgBrrfWSMMYFC7X1UAdwS5ljCbmtxJWU1dYzL7gX1dVBXZU8zG2NMgFB7H70pIr0D3qeLyBvhCys8cre7tvKx2WngK3MLrfrIGGMahVp9lOn1OAJAVfdwEM7RnLujhLjoKEb2TXVVR2DVR8YYEyDUpOAXkcZhLURkKEFGTe3ucreXcPiAVOJiolzPI7DeR8YYEyDUpPBr4EMReUpEngIWA79sbycRmS4i60Rkg4i02iYhIheIiIpITojx7DNVJXd7KWMbG5kbqo+spGCMMQ1CSgqq+jqQA6zD9UD6Ga4HUqtEJBq4DzgdGANcLCJjgmyXClwPLNunyPdR3p4qSqpqOSI7zS2wpGCMMS2EOiDeD4CfAIOAVcBUYAlNp+dsbgqwQVU3ecd4FjgXWNNsu/8C/gjctE+R76OGRuZx2V5JwaqPjDGmhVCrj34CTAa2quqJwCSgoJ19soFtAe/zvGWNRGQSMFhVAyfxaUFE5ojIChFZUVDQ3scGt6WokthoYVQ/r2RQY72PjDGmuVCTQrWqVgOISLyqfgkc1s4+EmRZY+O0iEQBf8ZVRbVJVR9S1RxVzcnKygox5KaunjaCT357Kgmx0W5BY++jtP06njHG9EShjl+U5z2n8DLwpojsof3pOPOAwQHvBzXbJxU4AnhPRAD6AwtF5BxVXRFiXPskNSH2mzcNzylY9ZExxjQK9Ynm73gvbxeRd4FewOvt7LYcGCkiw4DtwEXAJQHHLAEyG96LyHvATeFKCC3UlEF0HMTEdcrHGWPMwWCfRzpV1cUhblcnItcBbwDRwFxVXS0idwArVHXhvn52h7Jxj4wxpoWwDn+tqouARc2W3drKttPCGUsLNmy2Mca0EGpDc89jE+wYY0wLlhSMMcY0itykYNVHxhjTQuQmBZt1zRhjWojgpGC9j4wxprnITQq+cpt1zRhjmonMpOD3u6Rg1UfGGNNEZCYFn826ZowxwUR2UrDeR8YY00RkJgWbYMcYY4KK0KRg1UfGGBNMZCYFGzbbGGOCisykYLOuGWNMUBGaFKz6yBhjgonMpNDY+8iSgjHGBIrMpFBT6n5b9ZExxjQRoUmhHKJiICahqyMxxphuJTKTQsOw2SJdHYkxxnQrkZkUbIIdY4wJypKCMcaYRpGZFGzWNWOMCSoyk4LNumaMMUFFaFKwWdeMMSaYyEwKNuuaMcYEFZlJwaqPjDEmqMhLCqreVJxWUjDGmOYiLynUVoL6rfeRMcYEEXlJwYbNNsaYVkVgUmgYNjuta+MwxphuKPKSgs26ZowxrQprUhCR6SKyTkQ2iMgtQdb/VETWiMjnIvK2iAwJZzyAVR8ZY0wbwpYURCQauA84HRgDXCwiY5pt9imQo6rjgQXAH8MVTyObdc0YY1oVzpLCFGCDqm5SVR/wLHBu4Aaq+q6qVnpvlwKDwhiPY7OuGWNMq8KZFLKBbQHv87xlrbkSeC3YChGZIyIrRGRFQUHBgUVls64ZY0yrwpkUgs1go0E3FJkF5AD/G2y9qj6kqjmqmpOVlXVgUVn1kTHGtComjMfOAwYHvB8E7Gi+kYicAvwaOEFVa8IYj+MrB4mC2KSwf5QxxhxswllSWA6MFJFhIhIHXAQsDNxARCYB/wDOUdX8MMbyjZoym4rTGGNaEbakoKp1wHXAG8BaYL6qrhaRO0TkHG+z/wVSgOdFZJWILGzlcB3Hhs02xphWhbP6CFVdBCxqtuzWgNenhPPzg/KV2YNrxhjTish7otmGzTbGmFZFYFKw6iNjjGlN5CUFX7lVHxljTCsiLynUlFlJwRhjWmFJwRhjTKPISgoNU3Fa9ZExxgQVWUmhrhr8ddb7yBhjWhFZScFmXTPGmDZFVlKwWdeMMaZNkZUUbNY1Y4xpU4QlBRs22xhj2hJZScFmXTPGmDZFVlKw6iNjjGlTZCYFa2g2xpigIisp+KxNwRhj2hJZScFKCsYY06YISwrlEJsMUZH1tY0xJlSRdXX02WB4xhjTlshKCjbrmjHGtCnCkoKNkGqMMW2JrKTgs6k4jTGmLZGVFGyCHWOMaVPkJQWrPjLGmFZFVlKw6iNjjGlTZCUF631kjDFtipykUOeDep+NkGqMMW2InKRg4x4ZY0y7Iicp1JS631Z9ZIwxrYqgpNAwwY4lBWOMaU3kJAWrPjLGmHZFTlJonHXNkoIxxrQmrElBRKaLyDoR2SAitwRZHy8iz3nrl4nI0LAFY3MpGGNMu8KWFEQkGrgPOB0YA1wsImOabXYlsEdVDwX+DPwhXPFY9ZExxrQvnCWFKcAGVd2kqj7gWeDcZtucCzzhvV4AnCwiEpZoGquPrKRgjDGtCWdSyAa2BbzP85YF3UZV64ASIKP5gURkjoisEJEVBQUF+xdN+lAYfbY9vGaMMW0IZ1IIdsev+7ENqvqQquaoak5WVtb+RXP4mXDhPyE6Zv/2N8aYCBDOpJAHDA54PwjY0do2IhID9AKKwxiTMcaYNoQzKSwHRorIMBGJAy4CFjbbZiHwPe/1BcA7qtqipGCMMaZzhK0uRVXrROQ64A0gGpirqqtF5A5ghaouBB4FnhKRDbgSwkXhiscYY0z7wlrBrqqLgEXNlt0a8Loa+G44YzDGGBO6yHmi2RhjTLssKRhjjGlkScEYY0wjSwrGGGMaycHWA1RECoCt+7l7JlDYgeH0BHZOgrPz0pKdk5YOpnMyRFXbffr3oEsKB0JEVqhqTlfH0Z3YOQnOzktLdk5a6onnxKqPjDHGNLKkYIwxplGkJYWHujqAbsjOSXB2Xlqyc9JSjzsnEdWmYIwxpm2RVlIwxhjTBksKxhhjGkVMUhCR6SKyTkQ2iMgtXR1PVxCRuSKSLyK5Acv6iMibIrLe+53elTF2NhEZLCLvishaEVktIj/xlkfseRGRBBH5WEQ+887J77zlw0RkmXdOnvOGxI8oIhItIp+KyKve+x53TiIiKYhINHAfcDowBrhYRMZ0bVRd4nFgerNltwBvq+pI4G3vfSSpA36mqqOBqcC13v+NSD4vNcBJqjoBmAhMF5GpwB+AP3vnZA9wZRfG2FV+AqwNeN/jzklEJAVgCrBBVTepqg94Fji3i2PqdKr6Pi1ntjsXeMJ7/QRwXqcG1cVUdaeqfuK9LsP9wWcTwedFnXLvbaz3o8BJwAJveUSdEwARGQScCTzivRd64DmJlKSQDWwLeJ/nLTPQT1V3grtAAn27OJ4uIyJDgUnAMiL8vHjVJKuAfOBNYCOwV1XrvE0i8W/oL8AvAL/3PoMeeE4iJSlIkGXWF9c0EpEU4AXgBlUt7ep4upqq1qvqRNzc6lOA0cE269youo6InAXkq+rKwMVBNj3oz0lYZ17rRvKAwQHvBwE7uiiW7ma3iAxQ1Z0iMgB3ZxhRRCQWlxCeVtUXvcURf14AVHWviLyHa2/pLSIx3p1xpP0NHQOcIyJnAAlAGq7k0OPOSaSUFJYDI72eAnG4uaAXdnFM3cVC4Hve6+8Br3RhLJ3Oqxd+FFirqvcErIrY8yIiWSLS23udCJyCa2t5F7jA2yyizomq/lJVB6nqUNz14x1VvZQeeE4i5olmL8P/BYgG5qrq77s4pE4nIs8A03DD/e4GbgNeBuYDhwBfA99V1eaN0T2WiBwLfAB8wTd1xb/CtStE5HkRkfG4RtNo3I3jfFW9Q0SG4zpp9AE+BWapak3XRdo1RGQacJOqntUTz0nEJAVjjDHti5TqI2OMMSGwpGCMMaaRJQVjjDGNLCkYY4xpZEnBGGNMI0sKxnQiEZnWMMKmMd2RJQVjjDGNLCkYE4SIzPLmFFglIv/wBogrF5E/icgnIvK2iGR5204UkaUi8rmIvNQw94KIHCoib3nzEnwiIiO8w6eIyAIR+VJEnvaeqjamW7CkYEwzIjIauBA4xhsUrh64FEgGPlHVI4HFuCfCAZ4EblbV8bgnoxuWPw3c581L8G1gp7d8EnADbm6P4bhxdYzpFiJlQDxj9sXJwFHAcu8mPhE3IJ4feM7b5p/AiyLSC+itqou95U8Az4tIKpCtqi8BqGo1gHe8j1U1z3u/ChgKfBj+r2VM+ywpGNOSAE+o6i+bLBT5bbPt2hojpq0qocCxceqxv0PTjVj1kTEtvQ1cICJ9oXG+5iG4v5eGETEvAT5U1RJgj4gc5y2/DFjszcmQJyLneceIF5GkTv0WxuwHu0MxphlVXSMivwH+LSJRQC1wLVABjBWRlUAJrt0B3JDJD3oX/U3AbG/5ZcA/ROQO7xjf7cSvYcx+sVFSjQmRiJSrakpXx2FMOFn1kTHGmEZWUjDGGNPISgrGGGMaWVIwxhjTyJKCMcaYRpYUjDHGNLKkYIwxptH/B6rvHy8Q/IDMAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import tensorflow as tf \n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, Activation, Flatten, Conv2D, MaxPooling2D\n",
    "import pickle\n",
    "from tensorflow.keras.models import model_from_json\n",
    "from tensorflow.keras.models import load_model\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Opening the files about data\n",
    "X = pickle.load(open(\"X.pickle\", \"rb\"))\n",
    "y = pickle.load(open(\"y.pickle\", \"rb\"))\n",
    "\n",
    "# normalizing data (a pixel goes from 0 to 255)\n",
    "X = X/255.0\n",
    "\n",
    "# Building the model\n",
    "model = Sequential()\n",
    "# 3 convolutional layers\n",
    "model.add(Conv2D(32, (3, 3), input_shape = X.shape[1:]))\n",
    "model.add(Activation(\"relu\"))\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "\n",
    "model.add(Conv2D(64, (3, 3)))\n",
    "model.add(Activation(\"relu\"))\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "\n",
    "model.add(Conv2D(64, (3, 3)))\n",
    "model.add(Activation(\"relu\"))\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "# 2 hidden layers\n",
    "model.add(Flatten())\n",
    "model.add(Dense(128))\n",
    "model.add(Activation(\"relu\"))\n",
    "\n",
    "model.add(Dense(128))\n",
    "model.add(Activation(\"relu\"))\n",
    "\n",
    "# The output layer with 13 neurons, for 13 classes\n",
    "model.add(Dense(13))\n",
    "model.add(Activation(\"softmax\"))\n",
    "\n",
    "# Compiling the model using some basic parameters\n",
    "model.compile(loss=\"sparse_categorical_crossentropy\",\n",
    "\t\t\t\toptimizer=\"adam\",\n",
    "\t\t\t\tmetrics=[\"accuracy\"])\n",
    "\n",
    "# Training the model, with 40 iterations\n",
    "# validation_split corresponds to the percentage of images used for the validation phase compared to all the images\n",
    "history = model.fit(X, y, batch_size=32, epochs=45, validation_split=0.1)\n",
    "\n",
    "# Saving the model\n",
    "model_json = model.to_json()\n",
    "with open(\"model.json\", \"w\") as json_file :\n",
    "\tjson_file.write(model_json)\n",
    "\n",
    "model.save_weights(\"model.h5\")\n",
    "print(\"Saved model to disk\")\n",
    "\n",
    "model.save('CNN3.model')\n",
    "\n",
    "# Printing a graph showing the accuracy changes during the training phase\n",
    "print(history.history.keys())\n",
    "plt.figure(1)\n",
    "plt.plot(history.history['acc'])\n",
    "plt.plot(history.history['val_acc'])\n",
    "plt.title('model accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'validation'], loc='upper left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\Adi\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\resource_variable_ops.py:435: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:From C:\\Users\\Adi\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\layers\\core.py:143: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "Credit_card\n"
     ]
    }
   ],
   "source": [
    "def prepare(file):\n",
    "    IMG_SIZE = 100\n",
    "    img_array = cv2.imread(file, cv2.IMREAD_GRAYSCALE)\n",
    "    new_array = cv2.resize(img_array, (IMG_SIZE, IMG_SIZE))\n",
    "    return new_array.reshape(-1, IMG_SIZE, IMG_SIZE, 1)\n",
    "model = tensorflow.keras.models.load_model(\"CNN3.model\")\n",
    "image = prepare(\"data/test/x.png\")\n",
    "prediction = model.predict([image])\n",
    "prediction = list(prediction[0])\n",
    "print(CATEGORIES[prediction.index(max(prediction))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "pathF = \"data/test/x.png\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X\n",
      "(280, 498, 3)\n",
      "Credit Card #: 4004123456939310\n",
      "Credit Card Type: Visa\n"
     ]
    }
   ],
   "source": [
    "if CATEGORIES[prediction.index(max(prediction))] == \"Credit_card\":\n",
    "    print(\"X\")\n",
    "    from imutils import contours\n",
    "    import numpy as np\n",
    "    import argparse\n",
    "    import imutils\n",
    "    import cv2\n",
    "    import base64\n",
    "    import os\n",
    "    from cryptography.hazmat.backends import default_backend\n",
    "    from cryptography.hazmat.primitives import hashes\n",
    "    from cryptography.hazmat.primitives.kdf.pbkdf2 import PBKDF2HMAC\n",
    "    from cryptography.fernet import Fernet\n",
    "    from PIL import Image\n",
    "    import pytesseract\n",
    "\n",
    "    def getInput():\n",
    "\n",
    "        FIRST_NUMBER = {\n",
    "            \"1\": \"Unknown\",\n",
    "            \"2\": \"Unknown\",\n",
    "            \"3\": \"American Express\",\n",
    "            \"4\": \"Visa\",\n",
    "            \"5\": \"MasterCard\",\n",
    "            \"6\": \"Discover Card\",\n",
    "            \"7\": \"Unknown\",\n",
    "            \"8\": \"Unknown\",\n",
    "            \"9\": \"Unknown\",\n",
    "            \"0\": \"Unknown\",\n",
    "        }\n",
    "        computerVision(FIRST_NUMBER)\n",
    "\n",
    "\n",
    "    def computerVision(FIRST_NUMBER):\n",
    "        ref = cv2.imread(\"images/OCR_Images/ocr_a.png\")\n",
    "        ref = cv2.cvtColor(ref, cv2.COLOR_BGR2GRAY)\n",
    "        ref = cv2.threshold(ref, 10, 255, cv2.THRESH_BINARY_INV)[1]\n",
    "\n",
    "        refCnts = cv2.findContours(ref.copy(), cv2.RETR_EXTERNAL,\n",
    "                                   cv2.CHAIN_APPROX_SIMPLE)\n",
    "        refCnts = imutils.grab_contours(refCnts)\n",
    "        refCnts = contours.sort_contours(refCnts, method=\"left-to-right\")[0]\n",
    "        digits = {}\n",
    "\n",
    "        # Przejście pętli przez kontury zdjęcia referencyjnego\n",
    "        for (i, c) in enumerate(refCnts):\n",
    "            # Wyszukiwanie liczb, wyodrębnianie ich i dopasowanie wielkości\n",
    "            (x, y, w, h) = cv2.boundingRect(c)\n",
    "            roi = ref[y:y + h, x:x + w]\n",
    "            roi = cv2.resize(roi, (57, 88))\n",
    "\n",
    "            # zaktualizowanie bazy cyfr, mapowanie nazw cyfr do ROI\n",
    "            digits[i] = roi\n",
    "\n",
    "        # inicjalizacja kernela\n",
    "        rectKernel = cv2.getStructuringElement(cv2.MORPH_RECT, (9, 3))\n",
    "        sqKernel = cv2.getStructuringElement(cv2.MORPH_RECT, (5, 5))\n",
    "\n",
    "        # Wczytanie zdjęcia, dopasowanie wielkości i konwersja w skali szarości\n",
    "        image = cv2.imread(pathF)\n",
    "        height, width, channels = image.shape\n",
    "        image = imutils.resize(image, width=300)\n",
    "        gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "        tophat = cv2.morphologyEx(gray, cv2.MORPH_TOPHAT, rectKernel)\n",
    "\n",
    "        # obliczanie gradientu Scharra i przeskalowanie\n",
    "        # compute the Scharr gradient of the tophat image, then scale\n",
    "        gradX = cv2.Sobel(tophat, ddepth=cv2.CV_32F, dx=1, dy=0,\n",
    "                          ksize=-1)\n",
    "        gradX = np.absolute(gradX)\n",
    "        (minVal, maxVal) = (np.min(gradX), np.max(gradX))\n",
    "        gradX = (255 * ((gradX - minVal) / (maxVal - minVal)))\n",
    "        gradX = gradX.astype(\"uint8\")\n",
    "\n",
    "        # Zastosowanie operacji zamykania za pomocą Kernela w celu\n",
    "        # zamknięcia luk pomiędzy cyframi w kartach kredytowych\n",
    "        # binaryzacja obrazu metodą Otsu\n",
    "\n",
    "        gradX = cv2.morphologyEx(gradX, cv2.MORPH_CLOSE, rectKernel)\n",
    "        thresh = cv2.threshold(gradX, 0, 255,\n",
    "                               cv2.THRESH_BINARY | cv2.THRESH_OTSU)[1]\n",
    "\n",
    "        # Zastosowanie drugiej operacji zamykania dla zdjęcia zbinaryzowanego\n",
    "        # aby unikac luk między cyframi\n",
    "\n",
    "        thresh = cv2.morphologyEx(thresh, cv2.MORPH_CLOSE, sqKernel)\n",
    "\n",
    "        # znajdywanie konturów na obrazie progowym, nastepnie inicjalizowanie\n",
    "        # listy lokalizacji cyfr\n",
    "\n",
    "        cnts = cv2.findContours(thresh.copy(), cv2.RETR_EXTERNAL,\n",
    "                                cv2.CHAIN_APPROX_SIMPLE)\n",
    "        cnts = imutils.grab_contours(cnts)\n",
    "        locs = []\n",
    "\n",
    "        # przechodzenie pętli po konturach\n",
    "        for (i, c) in enumerate(cnts):\n",
    "            # przejście pętli przez kontury nastepnie użycie ramki ograniczającej\n",
    "            # i wyznaczenie współczynnika kształtu\n",
    "\n",
    "            (x, y, w, h) = cv2.boundingRect(c)\n",
    "            ar = w / float(h)\n",
    "\n",
    "            # karty kredytowe używają czcionki o stałym rozmiarze i są w 4 grupach\n",
    "            # przycinanie kontur na podstawie współczynnika kształtu\n",
    "            if 2.5 < ar < 4.0:\n",
    "                # kontury można przycinać przy różnej szerokości\n",
    "                if (40 < w < 55) and (10 < h < 20):\n",
    "                    # dołączenie regionu ramki granicznej zawierającej grupy cyfr\n",
    "                    locs.append((x, y, w, h))\n",
    "\n",
    "        # posortowanie lokalizacji cyfr od lewej do prawej a następnie inicjalizowanie\n",
    "        # listy sklasyfikowanych cyfr\n",
    "\n",
    "        locs = sorted(locs, key=lambda x: x[0])\n",
    "        output = []\n",
    "\n",
    "        # Pętla przechodząca przez 4 cyfry 4 grup\n",
    "        for (i, (gX, gY, gW, gH)) in enumerate(locs):\n",
    "            # inicjalizacja listy zgrupowanych cyfr\n",
    "            groupOutput = []\n",
    "\n",
    "            # wyodrębnienie grupy 4 cyfr ze zdjęcia w skali szarości\n",
    "            # implementacja progu w celu oddzielenia cyfr od tła karty kredytowej\n",
    "\n",
    "            group = gray[gY - 5:gY + gH + 5, gX - 5:gX + gW + 5]\n",
    "            group = cv2.threshold(group, 0, 255,\n",
    "                                  cv2.THRESH_BINARY | cv2.THRESH_OTSU)[1]\n",
    "\n",
    "            # rozpoznawanie każdej pojedycznej liczby z grupy\n",
    "            # sortowanie kontur od lewej do prawej\n",
    "            digitCnts = cv2.findContours(group.copy(), cv2.RETR_EXTERNAL,\n",
    "                                         cv2.CHAIN_APPROX_SIMPLE)\n",
    "            digitCnts = imutils.grab_contours(digitCnts)\n",
    "            digitCnts = contours.sort_contours(digitCnts,\n",
    "                                               method=\"left-to-right\")[0]\n",
    "\n",
    "            # pętla po konturach cyfr\n",
    "            for c in digitCnts:\n",
    "                # obliczanie konturów dla pojedynczych cyfr, wyodręnienie\n",
    "                # i dopasowanie do cyfr zdjęcia referencyjnego\n",
    "                (x, y, w, h) = cv2.boundingRect(c)\n",
    "                roi = group[y:y + h, x:x + w]\n",
    "                roi = cv2.resize(roi, (57, 88))\n",
    "\n",
    "                # inicjalizacja wyników pasujących do szablonu\n",
    "                scores = []\n",
    "\n",
    "                # przejście pętli przez zdjęcie referencyjne\n",
    "                for (digit, digitROI) in digits.items():\n",
    "                    # zastosowanie dopasowania szablonu opertego na korelacji\n",
    "                    # zaktualizowanie listy wyników\n",
    "                    result = cv2.matchTemplate(roi, digitROI,\n",
    "                                               cv2.TM_CCOEFF)\n",
    "                    (_, score, _, _) = cv2.minMaxLoc(result)\n",
    "                    scores.append(score)\n",
    "\n",
    "                # klasyfikacja dla cyfr będzie odniesieniem\n",
    "                # nazwa cyfry z najlepszym wynikiem dopasowania\n",
    "                groupOutput.append(str(np.argmax(scores)))\n",
    "\n",
    "                # wyrysowanie konturów rozróżniających grupy cyfr\n",
    "                # wyświetlenie zczytanych wartości z karty\n",
    "                # cv2.rectangle(image, (gX - 5, gY - 5),\n",
    "                #               (gX + gW + 5, gY + gH + 5), (0, 0, 255), 2)\n",
    "                # cv2.putText(image, \"\".join(groupOutput), (gX, gY - 15),\n",
    "                #             cv2.FONT_HERSHEY_SIMPLEX, 0.65, (0, 0, 255), 2)\n",
    "                cv2.rectangle(image, (gX, gY),\n",
    "                              (gX + gW, gY + gH), (0, 0, 0), 15)\n",
    "\n",
    "            output.extend(groupOutput)\n",
    "        print(\"Credit Card #: {}\".format(\"\".join(output)))\n",
    "        print(\"Credit Card Type: {}\".format(FIRST_NUMBER[(output[0])]))\n",
    "        readHosterName(output, image, FIRST_NUMBER, pathF)\n",
    "\n",
    "\n",
    "    def readHosterName(output,image, FIRST_NUMBER, pathF):\n",
    "        pytesseract.pytesseract.tesseract_cmd = r'C:\\Program Files\\Tesseract-OCR\\tesseract.exe'\n",
    "        img = Image.open(pathF)\n",
    "        text = pytesseract.image_to_string(img)\n",
    "        if not text :\n",
    "            hostName = \"\".encode()\n",
    "        else:\n",
    "            lastLine = [i for i in text.split('\\n') if i != ''][-1]\n",
    "            hostName = lastLine.encode()\n",
    "        encryptCardNumber(output, image, hostName, FIRST_NUMBER, pathF)\n",
    "\n",
    "\n",
    "    def encryptCardNumber(output, image, hostName, FIRST_NUMBER, pathF):\n",
    "        password_provided = \"\".join(output)\n",
    "\n",
    "        password = password_provided.encode()\n",
    "        salt = b'salt_'\n",
    "        kdf = PBKDF2HMAC(\n",
    "            algorithm=hashes.SHA256(),\n",
    "            length=32,\n",
    "            salt=salt,\n",
    "            iterations=100000,\n",
    "            backend=default_backend()\n",
    "        )\n",
    "        key = base64.urlsafe_b64encode(kdf.derive(password))\n",
    "\n",
    "        typeOfCreditCard = FIRST_NUMBER[output[0]].encode()\n",
    "\n",
    "        message = \"\".join(output).encode()\n",
    "        Fernet.generate_key()\n",
    "        f = Fernet(key)\n",
    "        encrypted = f.encrypt(message)\n",
    "        writeDataToFile(encrypted, image, typeOfCreditCard, hostName, pathF)\n",
    "\n",
    "\n",
    "    def writeDataToFile(encrypted, image, typeOfCreditCard, hostName, pathF):\n",
    "        fileW = open('key.key', 'ab')\n",
    "        fileR = open('key.key', 'r')\n",
    "        path = pathF.encode()\n",
    "        if pathF in fileR.read():\n",
    "            pass\n",
    "        else:\n",
    "            fileW.write(\n",
    "                b\"\\n\" + b\"Path: \" + path +\n",
    "                b\"\\n\" + b\"\\t\" + b\"Credit card number: \" + encrypted +\n",
    "                b\"\\n\" + b\"\\t\" + b\"Credit card type: \" + typeOfCreditCard +\n",
    "                b\"\\n\" + b\"\\t\" + b\"Hoster's name: \" + hostName)\n",
    "            fileW.close()\n",
    "        cv2.imshow(\"Image\", image)\n",
    "        cv2.waitKey(0)\n",
    "\n",
    "    getInput()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
